{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5103,
     "status": "ok",
     "timestamp": 1739231578150,
     "user": {
      "displayName": "Danielle Killeen",
      "userId": "01156062824676845723"
     },
     "user_tz": 360
    },
    "id": "s5WSnhRW0Yfi",
    "outputId": "681e032b-d0bb-4a72-a7e8-e14e20df0fc5"
   },
   "outputs": [],
   "source": [
    "!pip install xarray netCDF4 h5netcdf h5py requests dask --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1739231601210,
     "user": {
      "displayName": "Danielle Killeen",
      "userId": "01156062824676845723"
     },
     "user_tz": 360
    },
    "id": "fbp9DqOb0wTX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# NOAA OISST v2.1 Data URL\n",
    "BASE_URL = \"https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr\"\n",
    "\n",
    "# Directories\n",
    "RAW_DIR = \"/content/oisst_raw\"\n",
    "SUBSET_DIR = \"/content/oisst_california_subset\"\n",
    "MERGED_FILE = \"/content/oisst_california_1981_2025.nc\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "os.makedirs(SUBSET_DIR, exist_ok=True)\n",
    "\n",
    "# Define years & months to download\n",
    "YEARS = range(1981, 2026)\n",
    "MONTHS = range(1, 13)\n",
    "\n",
    "# Define California Coast region\n",
    "LAT_RANGE = slice(30, 42)  # 30¬∞N to 42¬∞N\n",
    "LON_RANGE = slice(230, 245)  # Convert -130¬∞W to -115¬∞W (360¬∞ system)\n",
    "\n",
    "# Minimum valid NetCDF file size (100 KB threshold)\n",
    "MIN_VALID_SIZE = 100_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 472739,
     "status": "ok",
     "timestamp": 1739231111474,
     "user": {
      "displayName": "Danielle Killeen",
      "userId": "01156062824676845723"
     },
     "user_tz": 360
    },
    "id": "9bsUYbg609jK",
    "outputId": "33d675e6-42a0-4dc1-d021-91da0635d9c2"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "for year in YEARS:\n",
    "    for month in MONTHS:\n",
    "        date_str = f\"{year}{month:02d}01\"\n",
    "        month_str = f\"{year}{month:02d}\"\n",
    "\n",
    "        file_url = f\"{BASE_URL}/{month_str}/oisst-avhrr-v02r01.{date_str}.nc\"\n",
    "        output_file = os.path.join(RAW_DIR, f\"oisst-avhrr-v02r01.{date_str}.nc\")\n",
    "\n",
    "        # Skip existing valid files\n",
    "        if os.path.exists(output_file) and os.path.getsize(output_file) > MIN_VALID_SIZE:\n",
    "            print(f\"‚úÖ Already exists: {output_file}\")\n",
    "            continue\n",
    "\n",
    "        # Check if file exists on NOAA server\n",
    "        response = requests.head(file_url)\n",
    "        if response.status_code == 404:\n",
    "            print(f\"‚ùå File not found: {file_url}\")\n",
    "            continue\n",
    "\n",
    "        # Download the file\n",
    "        print(f\"üîΩ Downloading {file_url} ...\")\n",
    "        os.system(f\"wget -q -O {output_file} {file_url}\")\n",
    "\n",
    "        # Validate download size\n",
    "        if os.path.getsize(output_file) < MIN_VALID_SIZE:\n",
    "            print(f\"‚ùå File too small, deleting: {output_file}\")\n",
    "            os.remove(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46498,
     "status": "ok",
     "timestamp": 1739231658763,
     "user": {
      "displayName": "Danielle Killeen",
      "userId": "01156062824676845723"
     },
     "user_tz": 360
    },
    "id": "sI7Ki8Ha2WhG",
    "outputId": "16059014-d49f-4d4a-a85d-2e7d6b2a2046"
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import gc\n",
    "\n",
    "subset_files = []\n",
    "batch_size = 5  # Process in batches of 5\n",
    "\n",
    "file_list = sorted([f for f in os.listdir(RAW_DIR) if f.endswith(\".nc\")])\n",
    "\n",
    "for i in range(0, len(file_list), batch_size):\n",
    "    batch = file_list[i:i+batch_size]\n",
    "    print(f\"\\nüîπ Processing batch {i//batch_size + 1}/{len(file_list)//batch_size + 1}...\")\n",
    "\n",
    "    for file in batch:\n",
    "        file_path = os.path.join(RAW_DIR, file)\n",
    "\n",
    "        try:\n",
    "            # Open dataset with chunking to reduce memory use\n",
    "            ds = xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"time\": 1})\n",
    "\n",
    "            # Subset region (California Coast)\n",
    "            ds_subset = ds.sel(lat=LAT_RANGE, lon=LON_RANGE)\n",
    "\n",
    "            # Keep only SST variable\n",
    "            ds_subset = ds_subset[[\"sst\"]]\n",
    "\n",
    "            # Save subset file\n",
    "            subset_file_path = os.path.join(SUBSET_DIR, file)\n",
    "            ds_subset.to_netcdf(subset_file_path)\n",
    "\n",
    "            # Close dataset to free memory\n",
    "            ds_subset.close()\n",
    "            ds.close()\n",
    "\n",
    "            subset_files.append(subset_file_path)\n",
    "            print(f\"‚úÖ Processed: {file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Skipping corrupt file: {file_path} | Error: {e}\")\n",
    "\n",
    "    # Manually clear memory after each batch\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\n‚úÖ All {len(subset_files)} files saved in {SUBSET_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4147,
     "status": "ok",
     "timestamp": 1739231666788,
     "user": {
      "displayName": "Danielle Killeen",
      "userId": "01156062824676845723"
     },
     "user_tz": 360
    },
    "id": "YgnMCD8T2nUt",
    "outputId": "ccefdaab-e1c1-4f48-c67b-6d3dc724021f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "subset_output_dir = \"/content/oisst_california_subset\"\n",
    "corrupt_files = []\n",
    "\n",
    "# Check all NetCDF files\n",
    "for file in sorted(os.listdir(subset_output_dir)):\n",
    "    if file.endswith(\".nc\"):\n",
    "        file_path = os.path.join(subset_output_dir, file)\n",
    "        try:\n",
    "            ds = xr.open_dataset(file_path, engine=\"netcdf4\")\n",
    "            ds.close()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Corrupt file detected: {file_path} | Error: {e}\")\n",
    "            corrupt_files.append(file_path)\n",
    "\n",
    "# Remove corrupted files\n",
    "if corrupt_files:\n",
    "    print(f\"\\nüö® Removing {len(corrupt_files)} corrupt files...\")\n",
    "    for bad_file in corrupt_files:\n",
    "        os.remove(bad_file)\n",
    "    print(\"‚úÖ Corrupt files deleted.\")\n",
    "else:\n",
    "    print(\"‚úÖ No corrupt files found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1739231669777,
     "user": {
      "displayName": "Danielle Killeen",
      "userId": "01156062824676845723"
     },
     "user_tz": 360
    },
    "id": "PU9ye9pC3PCZ",
    "outputId": "21431d54-a90a-41e3-cac7-40f873ffd66a"
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Pick two files to compare metadata\n",
    "file1 = \"/content/oisst_california_subset/oisst-avhrr-v02r01.20100501.nc\"\n",
    "file2 = \"/content/oisst_california_subset/oisst-avhrr-v02r01.20100601.nc\"\n",
    "\n",
    "# Open files\n",
    "ds1 = xr.open_dataset(file1, engine=\"netcdf4\")\n",
    "ds2 = xr.open_dataset(file2, engine=\"netcdf4\")\n",
    "\n",
    "# Compare dimensions\n",
    "print(\"\\nüîπ Dimensions in File 1:\")\n",
    "print(ds1.dims)\n",
    "print(\"\\nüîπ Dimensions in File 2:\")\n",
    "print(ds2.dims)\n",
    "\n",
    "# Compare coordinate variables\n",
    "print(\"\\nüîπ Coordinates in File 1:\")\n",
    "print(ds1.coords)\n",
    "print(\"\\nüîπ Coordinates in File 2:\")\n",
    "print(ds2.coords)\n",
    "\n",
    "# Compare attributes\n",
    "print(\"\\nüîπ Global attributes in File 1:\")\n",
    "print(ds1.attrs)\n",
    "print(\"\\nüîπ Global attributes in File 2:\")\n",
    "print(ds2.attrs)\n",
    "\n",
    "# Close datasets\n",
    "ds1.close()\n",
    "ds2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1739231678068,
     "user": {
      "displayName": "Danielle Killeen",
      "userId": "01156062824676845723"
     },
     "user_tz": 360
    },
    "id": "QJk9tV0a3g9_",
    "outputId": "e9e26209-e6ac-4c8f-8c3c-ed7b88e88250"
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "subset_output_dir = \"/content/oisst_california_subset\"\n",
    "nc_files = sorted([\n",
    "    os.path.join(subset_output_dir, f) for f in os.listdir(subset_output_dir) if f.endswith(\".nc\")\n",
    "])\n",
    "\n",
    "# Check time variable for each file\n",
    "for file in nc_files[:10]:  # Check first 10 files\n",
    "    ds = xr.open_dataset(file, engine=\"netcdf4\")\n",
    "    print(f\"\\nüîπ {file}\")\n",
    "    print(ds.time)\n",
    "    ds.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1739231684876,
     "user": {
      "displayName": "Danielle Killeen",
      "userId": "01156062824676845723"
     },
     "user_tz": 360
    },
    "id": "_9J4iizf3uIZ",
    "outputId": "310ec6a1-0536-408f-cf34-4625d92f7fa1"
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Select a few files for testing\n",
    "test_files = [\n",
    "    \"/content/oisst_california_subset/oisst-avhrr-v02r01.20100501.nc\",\n",
    "    \"/content/oisst_california_subset/oisst-avhrr-v02r01.20100601.nc\",\n",
    "    \"/content/oisst_california_subset/oisst-avhrr-v02r01.20100701.nc\",\n",
    "    \"/content/oisst_california_subset/oisst-avhrr-v02r01.20100801.nc\",\n",
    "    \"/content/oisst_california_subset/oisst-avhrr-v02r01.20100901.nc\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    ds_list = [xr.open_dataset(f, engine=\"netcdf4\") for f in test_files]\n",
    "    ds_combined = xr.concat(ds_list, dim=\"time\")  # Merge along time axis\n",
    "\n",
    "    print(\"‚úÖ Test merge successful!\")\n",
    "\n",
    "    # Close datasets\n",
    "    for ds in ds_list:\n",
    "        ds.close()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Merge failed! Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4305,
     "status": "ok",
     "timestamp": 1739231706137,
     "user": {
      "displayName": "Danielle Killeen",
      "userId": "01156062824676845723"
     },
     "user_tz": 360
    },
    "id": "yquVz31q5S-u",
    "outputId": "d2e0e596-84bb-4c4a-9e6a-00cd95709355"
   },
   "outputs": [],
   "source": [
    "!apt-get install -y nco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1739231713176,
     "user": {
      "displayName": "Danielle Killeen",
      "userId": "01156062824676845723"
     },
     "user_tz": 360
    },
    "id": "FFKc_fu35hdH",
    "outputId": "ae0df53e-6cfa-4bd6-b4f5-94d507f4eb9c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "subset_output_dir = \"/content/oisst_california_subset\"\n",
    "final_output_file = \"/content/oisst_california_1981_2025.nc\"\n",
    "\n",
    "# Get sorted list of valid NetCDF files\n",
    "valid_files = sorted([\n",
    "    os.path.join(subset_output_dir, f) for f in os.listdir(subset_output_dir) if f.endswith(\".nc\")\n",
    "])\n",
    "\n",
    "print(f\"\\nüîπ Merging {len(valid_files)} NetCDF files using `ncrcat`...\")\n",
    "\n",
    "# Merge using NCO (NetCDF Operators)\n",
    "merge_command = f\"ncrcat {' '.join(valid_files)} {final_output_file}\"\n",
    "os.system(merge_command)\n",
    "\n",
    "print(f\"‚úÖ Final dataset saved as {final_output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 865,
     "status": "ok",
     "timestamp": 1739231716872,
     "user": {
      "displayName": "Danielle Killeen",
      "userId": "01156062824676845723"
     },
     "user_tz": 360
    },
    "id": "NR8CwIVe5olM",
    "outputId": "6bf3902a-03c2-4ea7-d3c8-29d122c93175"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Move the final dataset\n",
    "!mv /content/oisst_california_1981_2025.nc /content/drive/MyDrive/oisst_california_1981_2025.nc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnUtZ5SN6fPA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMvKGwWXushi8MNqrtJxvFo",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
