---
title: "ARIMA_analysis"
output: html_document
---

```{r setup, include=FALSE}
# Set proper working directory (fixes reset issue in R Markdown)
knitr::opts_knit$set(root.dir = "C:/Users/samue/OneDrive/Documents/adsp31006-time-series-analysis")

# Load necessary libraries
library(tidyverse)
library(lubridate)
library(forecast)
library(tseries)
library(urca)
```


```{r}
# Load the dataset
data <- read.csv("C:/Users/samue/OneDrive/Documents/adsp31006-time-series-analysis/data/avg_sst_california.csv")

# Check structure
str(data)
head(data)

# Convert 'time' column to Date format
data$time <- as.Date(data$time, format="%m/%d/%Y %H:%M")

# Arrange by date
data <- data %>% arrange(time)

# Convert to time series (monthly frequency)
ts_data <- ts(data$sst, start = c(1981, 9), frequency = 12)

# Plot the time series
autoplot(ts_data) + 
  ggtitle("Monthly Sea Surface Temperature - California Coast") +
  ylab("Temperature (Â°C)") + xlab("Year")

# Get total number of observations
n <- length(ts_data)

# Train: All except last 12 months, Test: Last 12 months
train_data <- ts(ts_data[1:(n-12)], start = c(1981, 9), frequency = 12)
test_data  <- ts(ts_data[(n-11):n], start = c(end(ts_data)[1] - 1, end(ts_data)[2] + 1), frequency = 12)

# Plot Train vs Test split (Fix autolayer issue)
autoplot(train_data, series="Train", color="blue") +
  autolayer(test_data, series="Test", color="red") +
  ggtitle("Train-Test Split for SST Data") +
  ylab("Temperature (Â°C)") + xlab("Year")
```

```{r}
# Check if Box-Cox transformation is necessary
lambda <- BoxCox.lambda(train_data)
cat("Optimal Box-Cox lambda:", lambda, "\n")

#variance is increasing overtime = heteroskedasticity

train_transformed <- BoxCox(train_data, lambda = 0.0844185)

# Plot transformed data
autoplot(train_transformed) +
  ggtitle("Box-Cox Transformed Time Series") +
  xlab("Year") + ylab("Transformed Temperature")
```

```{r}

# Augmented Dickey-Fuller (ADF) Test on Train Data
adf_result <- adf.test(train_transformed)
print("ADF Test Result:")
print(adf_result)

# KPSS Test on Train Data
kpss_result <- ur.kpss(train_transformed)
print("KPSS Test Result:")
summary(kpss_result)

# Plot ACF and PACF for Train Data
tsdisplay(train_transformed, main="ACF and PACF of Train Data")


##Passes KPSS and ADF and says its stationary, but I think it will need seasonal differencing, which is obvious based on the seasonality in the ACF

```
Seasonal Differencing
```{r}
# Seasonal KPSS test to check for seasonality
seasonally_diff_train <- diff(train_transformed, lag=12)

par(mfrow=c(1,2))
Acf(seasonally_diff_train, lag.max=24, main="ACF after Seasonal Differencing")
Pacf(seasonally_diff_train, lag.max=24, main="PACF after Seasonal Differencing")

kpss_seasonal_test <- kpss.test(seasonally_diff_train, null = "Level")
print(kpss_seasonal_test)

adf_seasonal_test <- adf.test(seasonally_diff_train)
print("ADF Test Result:")
print(adf_result)
```

```{r}
# Fit the best Seasonal ARIMA model
best_sarima <- auto.arima(train_data, seasonal=TRUE, lambda = 0.0844185, approximation = FALSE, stepwise = FALSE)

# Display model summary
summary(best_sarima)

# Check residuals
checkresiduals(best_sarima)

```

```{r}
# test if residuals look like white noise
Box.test(residuals(best_sarima), lag=12, type="Ljung-Box")
```
The residuals do not reflect white noise, so more must be done.


Perhaps, there was over-differencing, and an ARFIMA model is needed for the residuals to fluctuate as white noise. This makes sense as the ACF was exponentially decaying VERY SLOWLY. Additionally, the ADF test and KPSS was passed for the transformed data, but that doesn't necessarily mean the data is stationary, as just because you reject the null doesn't mean that the time series is truly stationary; it only suggests that there is enough statistical evidence to reject the presence of a unit root. In particular, the ADF test has low power in detecting fractional integration, meaning that the series could still exhibit long memory behavior, where past values influence future values over an extended period rather than decaying quickly.

Given that the ACF was exponentially decaying very slowly, this suggests fractional differencing might be more appropriate than a standard ARIMA differencing approach. An ARFIMA (Autoregressive Fractionally Integrated Moving Average) model allows for fractional differencing (d) rather than restricting differencing to integer values (0, 1, or 2), which can better capture long memory dynamics in the data.

Thus, an ARFIMA model might be more suitable as it can:

Preserve more of the long-term dependency structure without over-differencing.
Avoid overdifferencing, which can lead to artificial stationarity and poor forecasting.
Better model slow-decaying autocorrelations that indicate long memory behavior.
ðŸš€ Next Step: Try estimating the fractional differencing parameter (d) using the arfima package in R and compare the model's performance with SARIMA.
```{r}
library(arfima)
library(fracdiff)

# Estimate fractional differencing order (d)
fd_result <- fracdiff(train_transformed)
d_estimate <- fd_result$d  # Extract estimated d

# Print estimated d value
cat("Estimated fractional differencing parameter (d):", d_estimate, "\n")

# Adjust d slightly below 0.5 if necessary
d_adjusted <- ifelse(is.na(d_estimate) | d_estimate >= 0.495, 0.49, d_estimate)

# Fit an ARFIMA model with adjusted d
best_arfima <- arfima(train_transformed, lmodel = list(dfrac = d_adjusted), order = c(1, 0, 1))

# Model summary
summary(best_arfima)

# Check residual diagnostics
checkresiduals(best_arfima)

# Ljung-Box test for white noise residuals
Box.test(residuals(best_arfima), type="Ljung-Box", lag=12)


```


```{r}
library(arfima)
library(fracdiff)

# Estimate fractional differencing order (d)
fd_result <- fracdiff(train_transformed)
d_estimate <- fd_result$d  

# Print estimated d value
cat("Estimated fractional differencing parameter (d):", d_estimate, "\n")

# Adjust d slightly below 0.5 if necessary
d_adjusted <- ifelse(is.na(d_estimate) | d_estimate >= 0.49, 0.48, d_estimate)

# Fit a simplified ARFIMA model (q=0)
best_arfima_simple <- arfima(train_transformed, lmodel = list(dfrac = d_adjusted), order = c(0, 0, 0))

# Model summary
summary(best_arfima_simple)

# Check residual diagnostics
checkresiduals(best_arfima_simple)

# Ljung-Box test for white noise residuals
Box.test(residuals(best_arfima_simple), type="Ljung-Box", lag=12)
```



